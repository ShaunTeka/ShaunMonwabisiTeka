{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "eQcsatYll2F4",
        "h7jeaWLbl4mw",
        "6MxvtIL51xMg",
        "LhvwCNB-7aLO",
        "arHsdxny1zbC",
        "EmzRzxG6E3XZ",
        "ZukedLC914Gx",
        "E7x9GInD19SG",
        "jka4IvgVKHxU",
        "sqlzmikq2Eib",
        "tQ1g4-wOMTCh",
        "HU9q1vCD2IY2",
        "Y4Y1vkgj2MRj",
        "4G7sA9U72U5j",
        "dX5kafmF2Yj1",
        "MSwBg4S9Rwup",
        "VxbpFkaK2aBf",
        "ZtVp-ndt2qkn",
        "R2bO8xmuZ3_y",
        "TeKF5rrJ20Zq",
        "IOs7hvq63eM-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunTeka/ShaunMonwabisiTeka/blob/main/Practice_GPT_4o_with_Python_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Sample Notebook] AfterWork: GPT-4o with Python Course"
      ],
      "metadata": {
        "id": "oh6fVQFPlugG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-requisites"
      ],
      "metadata": {
        "id": "eQcsatYll2F4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zZXhnmqlXzy",
        "outputId": "a5c65ada-de16-472d-94dd-47bb3b43e5ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.29.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.3/320.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.29.0\n"
          ]
        }
      ],
      "source": [
        "# Installing OpenAI Library\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the OpenAI Class\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "Cw3iJr3y1qsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting your API Key\n",
        "client = OpenAI(api_key=\"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\")"
      ],
      "metadata": {
        "id": "0kPrqZqn1uHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Text Generation and Analysis"
      ],
      "metadata": {
        "id": "h7jeaWLbl4mw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Zero-shot Prompting"
      ],
      "metadata": {
        "id": "6MxvtIL51xMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Zero-shot prompting is when a language model generates text without being provided with any specific examples or instructions related to the task at hand."
      ],
      "metadata": {
        "id": "kAV8bh6h63In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Zero-shot Prompting\n",
        "\n",
        "# Set up the prompt for the user\n",
        "prompt = \"Which bank collapsed in March 2023?\"\n",
        "\n",
        "# Send the prompt to the GPT-4o model to generate a response\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "# Get the response from the generated choices\n",
        "response = response.choices[0].message.content\n",
        "\n",
        "# Print the generated response\n",
        "print(response)"
      ],
      "metadata": {
        "id": "hjhMrMH-11mo",
        "outputId": "82ed6829-88d0-432a-9545-bca9faeed9df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In March 2023, Silicon Valley Bank (SVB) experienced a significant collapse. The bank, which primarily served technology startups and venture capital firms, faced a sudden and severe liquidity crisis. This led to a bank run, ultimately resulting in its failure. The incident had far-reaching implications for the tech industry and led to increased scrutiny of banking practices and regulations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge\n"
      ],
      "metadata": {
        "id": "LhvwCNB-7aLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write code to prompt GPT-4o to generate a creative story using zero-shot prompting."
      ],
      "metadata": {
        "id": "ZVT1U-Uw7fln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the use prompt\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Send the prompt to the GPT-4o model to generate a response\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Get the response from the generated choices\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Print the generated response\n",
        "# Write your code here\n",
        "\n"
      ],
      "metadata": {
        "id": "m4h0zxty7X_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Chain of Thought Prompting"
      ],
      "metadata": {
        "id": "arHsdxny1zbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain of thought prompting involves prompting an LLM to generate text that reflects the natural progression and flow of a person's thoughts on a given topic, often without strict constraints or specific instructions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2_Dgu1PFFKIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2.1 Chain of Thought Prompting\n",
        "\n",
        "# Set up the prompt for the user\n",
        "prompt = \"What is 100 degrees fahrenheit in degree celcius? Calculate step by step.\"\n",
        "\n",
        "# Send the prompt to the GPT-4o model to generate a response\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "# Get the response from the generated choices\n",
        "response = response.choices[0].message.content\n",
        "\n",
        "# Print the generated response\n",
        "print(response)"
      ],
      "metadata": {
        "id": "3I6-JJMl12iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge"
      ],
      "metadata": {
        "id": "EmzRzxG6E3XZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a prompt that requests the model to determined how many hours there are in 1 million minutes? Use chain of thought prompting."
      ],
      "metadata": {
        "id": "M6calNUkE4d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the prompt for the user\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Send the prompt to the GPT-4o model to generate a response\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Get the response from the generated choices\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Print the generated response\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "ms2TX0L1E2ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Reproducible Outputs"
      ],
      "metadata": {
        "id": "ZukedLC914Gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can sest the seed parameter to any integer of our choice and use the same value across requests we'd like deterministic outputs for."
      ],
      "metadata": {
        "id": "m-2m57zqGnqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3.1 Reproducible Outputs: Without the seed parameter\n",
        "\n",
        "# Set up the prompt for the user\n",
        "prompt = \"Which bank collapsed in March 2023?\"\n",
        "\n",
        "# Generate response\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Extract response message\n",
        "response1 = response.choices[0].message.content\n",
        "\n",
        "# Print response\n",
        "print(response1)"
      ],
      "metadata": {
        "id": "gpWGMZ6E17Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3.2 Reproducible Outputs: With the seed parameter\n",
        "\n",
        "# Set up the prompt for the user\n",
        "prompt = \"Which bank collapsed in March 2023?\"\n",
        "\n",
        "# Generate response\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    seed=1\n",
        ")\n",
        "\n",
        "# Extract response message\n",
        "response1 = response.choices[0].message.content\n",
        "\n",
        "# Print response\n",
        "print(response1)"
      ],
      "metadata": {
        "id": "3L298s8JF2vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Common Text Generation Tasks"
      ],
      "metadata": {
        "id": "E7x9GInD19SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4.0 Organizing the Code Using a Function\n",
        "\n",
        "# Creating the function\n",
        "def query_model(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        max_tokens=500,\n",
        "        temperature=0.0,\n",
        "        seed=1,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}])\n",
        "    return print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "tS3FyG5pHYxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4.1 Text Summarization\n",
        "\n",
        "# Defining the prompt\n",
        "prompt = \"\"\" Summarize the following text:\n",
        "\n",
        "              South America has an area of 17,840,000 square kilometers (6,890,000 sq mi).\n",
        "              Its population as of 2021 has been estimated at more than 434 million.\n",
        "              South America ranks fourth in area (after Asia, Africa, and North America)\n",
        "              and fifth in population (after Asia, Africa, Europe, and North America).\n",
        "              Brazil is by far the most populous South American country, with almost half\n",
        "              of the continent's population, followed by Colombia, Argentina, Venezuela and Peru.\n",
        "              In recent decades, Brazil has also generated half of the continent's GDP and\n",
        "              has become the continent's first regional power.\n",
        "              Most of the population lives near the continent's western or eastern coasts\n",
        "              while the interior and the far south are sparsely populated.\n",
        "              The geography of western South America is dominated by the Andes mountains;\n",
        "              in contrast, the eastern part contains both highland regions and vast\n",
        "              lowlands where rivers such as the Amazon, Orinoco and Paraná flow.\n",
        "              Most of the continent lies in the tropics, except for a large part\n",
        "              of the Southern Cone located in the middle latitudes.\"\"\"\n",
        "\n",
        "# Call the function\n",
        "query_model(prompt)"
      ],
      "metadata": {
        "id": "u88sJ7eY181b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4.2 Text Extraction\n",
        "\n",
        "# Perform text extraction\n",
        "prompt = \"\"\"Precisely extract any email addresses from the following text and then write them,\n",
        "            one per line. Only write an email address if it's precisely spelled out in the input text.\n",
        "            If there are no email addresses in the text, write \"N/A\". Do not say anything else.\n",
        "\n",
        "            Phone Directory:\n",
        "            John Latrabe, 555-232-1995, [john909709@geemail.com]\n",
        "            Josie Lana, 555-759-2905, [josie@josielananier.com]\n",
        "            Keven Stevens, 555-980-7000, [drkevin22@geemail.com]\n",
        "\n",
        "            Phone directory will be kept up to date by the HR manager.\"\"\"\n",
        "\n",
        "# Call the function\n",
        "query_model(prompt)"
      ],
      "metadata": {
        "id": "Matoizyo2B3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge"
      ],
      "metadata": {
        "id": "jka4IvgVKHxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write code with a new function that creates a poem given some text. The output should be deterministic."
      ],
      "metadata": {
        "id": "e6EsWZnvufGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's the text\n",
        "text = \"\"\"Fiji has long had permanent settlements, but its peoples also have a history of mobility.\n",
        "            Over the centuries, unique Fijian cultural practices developed. Fijians constructed large,\n",
        "            elegant watercraft, with rigged sails called drua and exported some to Tonga.\n",
        "            Fijians also developed a distinctive style of village architecture, consisting of\n",
        "            communal and individual bure and vale housing, and an advanced system of ramparts and\n",
        "            moats that were usually constructed around the more important settlements.\n",
        "            Pigs were domesticated for food, and a variety of agricultural endeavors, such as banana\n",
        "            plantations, existed from an early stage. Villages were supplied with water brought\n",
        "            in by constructed wooden aqueducts. Fijians lived in societies led by chiefs, elders\n",
        "            and notable warriors. Spiritual leaders, often called bete, were also important cultural figures,\n",
        "            and the production and consumption of yaqona was part of their ceremonial and community rites.\n",
        "            Fijians developed a monetary system where the polished teeth of the sperm whale, called tambua,\n",
        "            became an active currency. A type of writing existed which can be seen today\n",
        "            in various petroglyphs around the islands. Fijians developed a refined masi cloth textile industry,\n",
        "            and used the cloth they produced to make sails and clothes such as the malo and the liku.\n",
        "            As with most other ancient human civilisations, warfare or preparation for warfare was\n",
        "            an important part of everyday life in pre-colonial Fiji. The Fijians were noted for\n",
        "            their distinctive use of weapons, especially war clubs.\n",
        "            Fijians used many different types of clubs that can be broadly divided into two groups,\n",
        "            two handed clubs and small specialised throwing clubs called ula.\n",
        "        \"\"\"\n",
        "\n",
        "prompt = \"Create a poem given the following text: \" + text\n",
        "\n",
        "# Creating the function\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Call the function\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "P9d-4A5_KGTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Uploading PDF Documents"
      ],
      "metadata": {
        "id": "sqlzmikq2Eib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.5.1 Uploading PDF Documents\n",
        "\n",
        "# Install PyPDF2 library for working with PDF files\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "roA2quhB2GJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the PdfReader class from the PyPDF2 library\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "yOWKI_AQI_0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the PDF file (https://bit.ly/3WT7V6z) in binary read mode\n",
        "with open(\"African Tales.pdf\", \"rb\") as file:\n",
        "    # Create a PDF reader object\n",
        "    reader = PdfReader(file)\n",
        "\n",
        "    # Get the number of pages in the PDF\n",
        "    number_of_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page and concatenate\n",
        "    african_story = ''.join(page.extract_text() for page in reader.pages)\n",
        "\n",
        "    # Print the first 500 characters of the extracted text\n",
        "    print(african_story[:500])"
      ],
      "metadata": {
        "id": "yACJStJ-JBkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform summarization\n",
        "prompt = \"Summarize the following african story in 2 sentences: \" + african_story\n",
        "\n",
        "# Call the function with the inputs\n",
        "query_model(prompt)"
      ],
      "metadata": {
        "id": "Y2dr0Or-JHcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge"
      ],
      "metadata": {
        "id": "tQ1g4-wOMTCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and upload the following PDF document (https://bit.ly/3yazfTj) and thereafter write code that summarizes the text in the document in english."
      ],
      "metadata": {
        "id": "VCDsxVBzMWxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the PDF file (https://bit.ly/3yazfTj) in binary read mode\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Perform summarization\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Call the function with the inputs\n",
        "# Write your code here\n",
        "\n"
      ],
      "metadata": {
        "id": "Qkw6Vx5qMUUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Fetching Webpage Content"
      ],
      "metadata": {
        "id": "HU9q1vCD2IY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.6.1 Fething Wepage Content\n",
        "\n",
        "# Library for making HTTP requests\n",
        "import requests\n",
        "\n",
        "# Library for parsing HTML and XML documents\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "MuxL_gW62KVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(\"https://en.wikipedia.org/wiki/South_America\")\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find the main content area of the Wikipedia page\n",
        "    content_div = soup.find(\"div\", class_=\"mw-parser-output\")\n",
        "\n",
        "    # Extract text from the paragraphs\n",
        "    paragraphs = content_div.find_all(\"p\")\n",
        "\n",
        "    # Combine paragraphs until reaching a certain character limit\n",
        "    character_limit = 5000\n",
        "    current_length = 0\n",
        "    content = \"\"\n",
        "    for p in paragraphs:\n",
        "        text = p.get_text()\n",
        "        if current_length + len(text) <= character_limit:\n",
        "            content += text + \"\\n\"\n",
        "            current_length += len(text)\n",
        "        else:\n",
        "            break\n",
        "    print(content)\n",
        "else:\n",
        "    print(f\"Failed to fetch the web page. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "id": "CvJPayGcJqUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our prompt\n",
        "prompt = \"Please produce a concise summary of the following content:\" + content\n",
        "\n",
        "# Call the function with the inputs\n",
        "query_model(prompt)"
      ],
      "metadata": {
        "id": "dywpS3wBJt9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 JSON Mode"
      ],
      "metadata": {
        "id": "Y4Y1vkgj2MRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can instruct the model to always return a JSON object that makes sense for our use case, by specifying this in the system message."
      ],
      "metadata": {
        "id": "76ba9FodNe4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.7.1 JSON Mode\n",
        "\n",
        "# Defining the user prompt\n",
        "prompt = \"Which bank collapsed in March 2023?\"\n",
        "\n",
        "# Creating the function\n",
        "def query_json_model(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        max_tokens=500,\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        temperature=0.0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return print(response.choices[0].message.content)\n",
        "\n",
        "# Call the function\n",
        "query_json_model(prompt)"
      ],
      "metadata": {
        "id": "8bv8acHj2OG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Understanding Images"
      ],
      "metadata": {
        "id": "4G7sA9U72U5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the function to query the model\n",
        "def query_image_model(prompt, image_url):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        max_tokens=300,\n",
        "        temperature=0,\n",
        "        seed=10,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": image_url,\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "YiOvZlqTQN-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Analyzing an Image from a URL"
      ],
      "metadata": {
        "id": "dX5kafmF2Yj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JPEG Image\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"What's in the following image?\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://archive.org/download/1-png-image/1_jpeg_image.jpg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "1WJe7XAh2Zqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PNG (.png) Image\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"What's in the following image?\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://archive.org/download/1-png-image/1_png_image.png\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Pxdo9kBh2diR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WEBP (.webp) Image\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"What's in the following image?\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://archive.org/download/1-png-image/1_webp_image.webp\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "og5SBrSB2fa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-animated GIF (.gif) Image\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"What's in the following image?\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://archive.org/download/1-png-image/1_flowers_gif.gif\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "6sHVtpId2g5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge"
      ],
      "metadata": {
        "id": "MSwBg4S9Rwup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write code that provides a description of what's in the following JPEG image: https://images.pexels.com/photos/18771779/pexels-photo-18771779/free-photo-of-hill-and-town-on-sea-coast-of-amalfi.jpeg. The response should be non-deterministic."
      ],
      "metadata": {
        "id": "8i0uGde_R29f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the function to query the model\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "5S76KECiR7Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Uploading an Image to Analyze"
      ],
      "metadata": {
        "id": "VxbpFkaK2aBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2.1 Uploading an Image\n",
        "\n",
        "# We import the base64 module for encoding binary data\n",
        "import base64\n",
        "\n",
        "# We create the function to encode the image\n",
        "def encode_image(image_path):\n",
        "    \"\"\"\n",
        "    Encode the content of an image file into base64 format.\n",
        "\n",
        "    Parameters:\n",
        "    - image_path (str): The file path to the image.\n",
        "\n",
        "    Returns:\n",
        "    - str: The base64-encoded representation of the image.\n",
        "    \"\"\"\n",
        "    # We open the image file in binary mode\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "\n",
        "        # We read the binary content of the image file and encode it in base64\n",
        "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    # We return the base64-encoded image as a string\n",
        "    return encoded_image"
      ],
      "metadata": {
        "id": "WwwzqAQi2mZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a function to query the model\n",
        "def query_image_model_from_upload(prompt, base64_image):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=300,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "oSCKLAXETo1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text prompt\n",
        "prompt = \"What's in the following image?\"\n",
        "\n",
        "# Visit this link to download and later upload it:\n",
        "# https://archive.org/download/image_upload/image_upload.jpg\n",
        "\n",
        "# Image path\n",
        "image_path = \"image_upload.jpeg\"\n",
        "\n",
        "# Getting the base64 string\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model_from_upload(prompt, base64_image)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "D_hZXAMwUBFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a restriction of image uploads to 20MB per image."
      ],
      "metadata": {
        "id": "2NTWm6QzVWt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2.2 Image Size Limit\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"What's in the following image?\"\n",
        "\n",
        "# Visit this link to downoad and later upload it:\n",
        "# https://archive.org/download/greater_than_20/greater_than_20.png\n",
        "\n",
        "# Image path\n",
        "image_path = \"greater_than_20.png\"\n",
        "\n",
        "# Getting the base64 string\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model_from_upload(prompt, base64_image)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "AgnATzMd2nrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Analyzing Multiple Images"
      ],
      "metadata": {
        "id": "ZtVp-ndt2qkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3.1 Analyzing Multiple Images\n",
        "\n",
        "# Create a function to get image analysis response\n",
        "def query_image_model_multiple_images(prompt, image_urls):\n",
        "    # Construct a message object with a single user role and a text prompt\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": prompt},\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Append image URLs to the existing user role\n",
        "    for url in image_urls:\n",
        "        messages[0][\"content\"].append({\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "                \"url\": url,\n",
        "            },\n",
        "        })\n",
        "\n",
        "    # Create a chat completion request using the OpenAI API\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=300,\n",
        "    )\n",
        "\n",
        "    # Return the generated response content from the model\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "ZGMA4dRL2sKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text prompt\n",
        "prompt = \"What's in the following images?\"\n",
        "\n",
        "# List of image URLs\n",
        "image_urls = [\n",
        "    \"https://archive.org/download/multiple_image2/multiple_image1.jpeg\",\n",
        "    \"https://archive.org/download/multiple_image2/multiple_image2.jpeg\",\n",
        "]\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model_multiple_images(prompt, image_urls)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "hv94igI3ZYLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge"
      ],
      "metadata": {
        "id": "R2bO8xmuZ3_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write code with a function that provides a description of what's in the following images:\n",
        "* Image URL = https://images.pexels.com/photos/18962956/pexels-photo-18962956/free-photo-of-cakes-with-coffee.jpeg\n",
        "\n",
        "* Image URL = https://images.pexels.com/photos/18962949/pexels-photo-18962949/free-photo-of-sweet-cakes-and-coffee.jpeg"
      ],
      "metadata": {
        "id": "zWE7Mqb7Z59X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "6eR-hD4nZ69b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Searching for Information In An Image"
      ],
      "metadata": {
        "id": "TeKF5rrJ20Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4.1 Identifying Objects\n",
        "\n",
        "# Define the text prompt for object detection\n",
        "prompt = \"Detect and identify objects in the following image.\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://archive.org/download/search_image/search_image.jpeg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "rsPtDBGI24lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4.2 Counting\n",
        "\n",
        "# Define the text prompt for object detection\n",
        "prompt = \"From the image, give me the number of berries that are red.\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://archive.org/download/search_image/search_image.jpeg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "RUeQ3qdB26js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4.3 Advanced Prompt for Object Detection\n",
        "\n",
        "# Define the an advanced text prompt for object detection\n",
        "prompt = \"Give me the recipe for the bread in the following image.\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://images.pexels.com/photos/18783585/pexels-photo-18783585/free-photo-of-a-loaf-of-bread-with-a-christmas-decoration-on-it.jpeg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "4G1QZnKa2-Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4.3 Advanced Prompt for Object Detection\n",
        "\n",
        "# Define the an advanced text prompt for object detection\n",
        "prompt = \"What's the type of wedding dress found in the following image and give me steps of how is it made?\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://images.pexels.com/photos/291759/pexels-photo-291759.jpeg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "GXJ0hnRV2_S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4.4 Advanced Prompt for Object Detection\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"What's written on the card?\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://images.pexels.com/photos/2229237/pexels-photo-2229237.jpeg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "qi1Hr0I_doLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4.5 Translation\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"Translate the text found in the following photo.\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://images.pexels.com/photos/2506923/pexels-photo-2506923.jpeg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_image_model(prompt, image_url)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "-0bdXwh43OqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Fidelity Understanding"
      ],
      "metadata": {
        "id": "IOs7hvq63eM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By controlling the `detail` parameter, which has two options, low or high, you have control over how the model processes the image and generates its textual understanding.\n",
        "\n"
      ],
      "metadata": {
        "id": "ibKrBnSw0Qo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`low` will disable the “high res” mode. The model will receive a low-res `512 x 512` version of the image, and represent the image with a budget of 65 tokens. This allows the API to return faster responses and consume fewer input tokens for use cases that do not require high detail.\n"
      ],
      "metadata": {
        "id": "rHpS7ArD0Rl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.6.1 Fidelity Understanding\n",
        "\n",
        "def query_fid_model(prompt, image_url, detail):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": image_url,\n",
        "                            \"detail\": detail,\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=300,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "gh7QflJT3jLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.6.2 Low Fidelity Understanding\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"What's in the following image?\"\n",
        "\n",
        "# Disable the high resolution mode\n",
        "detail = \"low\"\n",
        "\n",
        "# Provide the image URL\n",
        "image_url = \"https://archive.org/download/1-png-image/1_jpeg_image.jpg\"\n",
        "\n",
        "# Call the function with the inputs\n",
        "result = query_fid_model(prompt, image_url, detail)\n",
        "\n",
        "# Print the generated response\n",
        "print(result)"
      ],
      "metadata": {
        "id": "vks-TAPJ3j9C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}